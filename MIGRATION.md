# LangChain 0.3 å‡çº§è¿ç§»æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†ä» LangChain 0.2.x å‡çº§åˆ° 0.3.x çš„è¿ç§»æ­¥éª¤å’Œæ³¨æ„äº‹é¡¹ã€‚

## ğŸ”„ ä¸»è¦å˜æ›´

### 1. LangGraph API å˜æ›´

#### é—®é¢˜ï¼šEND å¸¸é‡åºŸå¼ƒ
```python
# âŒ æ—§ç‰ˆæœ¬ (LangGraph < 0.2.20)
from langgraph.graph import StateGraph, END

workflow.add_edge("format_response", END)
workflow.add_conditional_edges(
    "agent",
    self._should_continue,
    {
        "continue": "tools",
        "end": END
    }
)
```

```python
# âœ… æ–°ç‰ˆæœ¬ (LangGraph >= 0.2.20)
from langgraph.graph import StateGraph

workflow.add_edge("format_response", "__end__")
workflow.add_conditional_edges(
    "agent",
    self._should_continue,
    {
        "continue": "tools",
        "end": "__end__"
    }
)
```

### 2. æ¨¡å‹è°ƒç”¨ API å˜æ›´

#### é—®é¢˜ï¼šagenerate æ–¹æ³•åºŸå¼ƒ
```python
# âŒ æ—§ç‰ˆæœ¬
result = await self.langchain_model.agenerate([messages])
generation = result.generations[0][0]
content = generation.text
```

```python
# âœ… æ–°ç‰ˆæœ¬
result = await self.langchain_model.ainvoke(messages)
content = result.content
```

### 3. æµå¼è°ƒç”¨ä¼˜åŒ–

#### é—®é¢˜ï¼šastream å‚æ•°ä¼ é€’
```python
# âŒ æ—§ç‰ˆæœ¬
async for chunk in self.langchain_model.astream(messages, **kwargs):
    yield chunk.content
```

```python
# âœ… æ–°ç‰ˆæœ¬
async for chunk in self.langchain_model.astream(messages):
    if hasattr(chunk, 'content') and chunk.content:
        yield chunk.content
```

### 4. Tokenç»Ÿè®¡æ”¹è¿›

#### é—®é¢˜ï¼šusage_metadata æ ¼å¼å˜æ›´
```python
# âŒ æ—§ç‰ˆæœ¬
if hasattr(result, 'llm_output') and result.llm_output:
    token_usage = result.llm_output.get('token_usage', {})
```

```python
# âœ… æ–°ç‰ˆæœ¬
if hasattr(result, 'usage_metadata') and result.usage_metadata:
    token_usage = {
        'input_tokens': result.usage_metadata.get('input_tokens', 0),
        'output_tokens': result.usage_metadata.get('output_tokens', 0),
        'total_tokens': result.usage_metadata.get('total_tokens', 0)
    }
```

## ğŸ”§ è¿ç§»æ­¥éª¤

### æ­¥éª¤1ï¼šæ›´æ–°ä¾èµ–

```bash
# å¸è½½æ—§ç‰ˆæœ¬
pip uninstall langchain langchain-core langchain-community langgraph

# å®‰è£…æ–°ç‰ˆæœ¬
pip install -r requirements.txt
```

### æ­¥éª¤2ï¼šä»£ç æ›´æ–°

1. **æ›´æ–° LangGraph å¯¼å…¥**
   ```python
   # åˆ é™¤ END å¯¼å…¥
   from langgraph.graph import StateGraph  # ç§»é™¤ END
   ```

2. **æ›´æ–°å›¾ç»“æŸèŠ‚ç‚¹**
   ```python
   # æ›¿æ¢æ‰€æœ‰ END ä¸º "__end__"
   workflow.add_edge("node_name", "__end__")
   ```

3. **æ›´æ–°æ¨¡å‹è°ƒç”¨**
   ```python
   # æ›¿æ¢ agenerate ä¸º ainvoke
   result = await model.ainvoke(messages)
   ```

### æ­¥éª¤3ï¼šæµ‹è¯•éªŒè¯

```bash
# è¿è¡Œå…¼å®¹æ€§æµ‹è¯•
python -m pytest tests/test_langchain_compatibility.py -v

# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
python -m pytest tests/ -v
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### ç ´åæ€§å˜æ›´

1. **LangGraph END å¸¸é‡åˆ é™¤**
   - å¿…é¡»æ›¿æ¢ä¸º `"__end__"` å­—ç¬¦ä¸²
   - å½±å“æ‰€æœ‰ä½¿ç”¨ LangGraph çš„æ™ºèƒ½ä½“

2. **æ¨¡å‹ API å˜æ›´**
   - `agenerate` æ–¹æ³•å·²åºŸå¼ƒ
   - å¿…é¡»ä½¿ç”¨ `ainvoke` æ›¿ä»£

3. **å“åº”æ ¼å¼å˜æ›´**
   - Token ç»Ÿè®¡ä¿¡æ¯ç»“æ„å˜æ›´
   - éœ€è¦æ›´æ–°ç›¸å…³è§£æä»£ç 

### å…¼å®¹æ€§æ£€æŸ¥

åœ¨å‡çº§åï¼Œè¯·ç¡®ä¿ï¼š

1. æ‰€æœ‰æ™ºèƒ½ä½“éƒ½èƒ½æ­£å¸¸åˆå§‹åŒ–
2. æµå¼è¾“å‡ºåŠŸèƒ½æ­£å¸¸
3. Token ç»Ÿè®¡æ˜¾ç¤ºæ­£ç¡®
4. é”™è¯¯å¤„ç†æœºåˆ¶æœ‰æ•ˆ

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.1.0 (2024-12-25)
- å‡çº§åˆ° LangChain 0.3
- ä¿®å¤ LangGraph END å¸¸é‡é—®é¢˜
- æ›´æ–°æ¨¡å‹è°ƒç”¨ API
- ä¼˜åŒ–æµå¼è¾“å‡ºå¤„ç†
- å¢å¼ºé”™è¯¯å¤„ç†å’Œæ—¥å¿—

## ğŸ”— ç›¸å…³èµ„æº

- [LangChain 0.3 å®˜æ–¹è¿ç§»æŒ‡å—](https://python.langchain.com/docs/versions/migrating_chains/)
- [LangGraph æ›´æ–°æ—¥å¿—](https://github.com/langchain-ai/langgraph/releases)
- [é¡¹ç›®æµ‹è¯•æ–‡æ¡£](tests/README.md)